# üß¨ Sistema de Entrenamiento y Evaluaci√≥n de Embeddings Biom√©dicos

## üìã Descripci√≥n del Proyecto

Este proyecto implementa un sistema completo para el entrenamiento, fine-tuning y evaluaci√≥n de modelos de embeddings especializados en el dominio biom√©dico. El objetivo es desarrollar embeddings que capturen mejor la sem√°ntica de textos m√©dicos en catal√°n y espa√±ol, mejorando significativamente el rendimiento en tareas de b√∫squeda sem√°ntica y recuperaci√≥n de informaci√≥n m√©dica.

## üéØ Objetivos

- **Fine-tuning de modelos biom√©dicos**: Adaptar modelos pre-entrenados al dominio m√©dico
- **Evaluaci√≥n comparativa**: Comparar el rendimiento de m√∫ltiples arquitecturas de modelos
- **Ensemble de embeddings**: Desarrollar estrategias de combinaci√≥n para mejorar la precisi√≥n
- **Optimizaci√≥n multiling√ºe**: Mejorar el rendimiento en catal√°n y espa√±ol
- **An√°lisis de rendimiento**: Evaluar m√©tricas de precisi√≥n, velocidad y eficiencia

## üèóÔ∏è Arquitectura del Sistema

### Componentes Principales

1. **Cargador de Modelos Unificado** (`cargador_models.py`)
   - Adaptador universal para modelos de Hugging Face
   - Soporte para m√∫ltiples estrategias de pooling (mean, CLS, max)
   - Detecci√≥n autom√°tica de dimensiones de embedding

2. **Sistema de Comparaci√≥n** (`comparacion_modelos_multiple.py`)
   - Evaluaci√≥n batch de m√∫ltiples modelos
   - M√©tricas de rendimiento estandarizadas
   - Generaci√≥n autom√°tica de reportes

3. **Sistema de Ensemble** (`comparar_esemble.py`)
   - Combinaci√≥n ponderada de embeddings
   - Fusi√≥n de rankings m√∫ltiples
   - Optimizaci√≥n autom√°tica de pesos

## üìä Metodolog√≠a

### 1. Preparaci√≥n de Datos

El sistema procesa **24 documentos m√©dicos** del sistema sanitario catal√°n, generando:

- **194 chunks** de texto con longitud promedio de 244 palabras
- **1,344 pares de entrenamiento** con distribuci√≥n de dificultad:
  - **Semi-hard**: 873 pares (65%)
  - **Hard**: 315 pares (23%)
  - **Easy**: 156 pares (12%)

### 2. Estrategia de Fine-tuning

#### Modelos Base Utilizados
- **BioBERT**: Variantes v1.1 y v1.2
- **BioClinicalBERT**: Especializado en textos cl√≠nicos
- **SapBERT**: Adaptado para UMLS y PubMed
- **PubMedBERT**: Versiones MS y MS-MARCO
- **DeBERTa-v3**: Configuraciones conservadora y agresiva
- **Biomedical-RoBERTa**: Especializado en espa√±ol
- **RoBERTa-Catalan**: Modelo base en catal√°n

#### Configuraciones de Entrenamiento
- **Estrategia conservadora**: Fine-tuning gradual con learning rates bajos
- **Estrategia agresiva**: Fine-tuning intensivo con learning rates altos
- **Early stopping**: Parada temprana basada en p√©rdida de validaci√≥n
- **Checkpoints m√∫ltiples**: Guardado de modelos en diferentes √©pocas

### 3. Evaluaci√≥n y M√©tricas

#### M√©tricas Principales
- **Accuracy@1**: Precisi√≥n en la primera posici√≥n
- **Accuracy@5**: Precisi√≥n en las primeras 5 posiciones
- **MRR (Mean Reciprocal Rank)**: Ranking rec√≠proco promedio
- **Similitud promedio**: Coeficiente de similitud coseno
- **Velocidad**: Tiempo de procesamiento por query

#### Conjunto de Prueba
- **48 queries** de prueba en espa√±ol y catal√°n
- **Evaluaci√≥n de recuperaci√≥n**: B√∫squeda sem√°ntica en corpus m√©dico
- **Comparaci√≥n contra modelo base**: all-MiniLM-base

## üèÜ Resultados Principales

### Rendimiento del Modelo Base
- **Accuracy@1**: 33.3%
- **Accuracy@5**: 52.1%
- **MRR**: 0.406
- **Similitud promedio**: 54.6%

### Top 5 Modelos Mejorados

| # | Modelo | Acc@1 | Mejora | Acc@5 | MRR | Velocidad |
|---|--------|-------|---------|-------|-----|-----------|
| 1 | **SapBERT-UMLS** | 64.6% | +31.3pp | 77.1% | 0.692 | 0.0059s |
| 2 | **Biomedical-RoBERTa** | 62.5% | +29.2pp | 66.7% | 0.642 | 0.0055s |
| 3 | **SapBERT-UMLS** | 62.5% | +29.2pp | 75.0% | 0.674 | 0.0055s |
| 4 | **SapBERT-UMLS** | 62.5% | +29.2pp | 75.0% | 0.678 | 0.0050s |
| 5 | **SapBERT-UMLS** | 62.5% | +29.2pp | 77.1% | 0.677 | 0.0052s |

### An√°lisis por Tipo de Modelo

#### Modelos de Mejor Rendimiento
- **SapBERT-UMLS**: Consistente en el top 10
- **Biomedical-RoBERTa**: Excelente para espa√±ol
- **SapBERT-PubMed**: Buen rendimiento general
- **MedCPT**: Especializado en consultas m√©dicas

#### Mejoras Promedio por Categor√≠a
- **Modelos biom√©dicos especializados**: +25-30pp
- **Modelos multiling√ºes**: +20-25pp
- **Modelos generales fine-tuneados**: +15-20pp

### Resultados del Ensemble

El sistema de ensemble logra mejoras adicionales mediante:

- **Combinaci√≥n ponderada**: Mejora del 5-10% sobre modelos individuales
- **Fusi√≥n de rankings**: Optimizaci√≥n de la precisi√≥n en top-k
- **Diversidad de modelos**: Reducci√≥n de overfitting

## üöÄ Caracter√≠sticas T√©cnicas

### Optimizaciones Implementadas
- **Pooling adaptativo**: Selecci√≥n autom√°tica de estrategia √≥ptima
- **Batch processing**: Procesamiento eficiente de m√∫ltiples modelos
- **Caching de embeddings**: Reutilizaci√≥n de embeddings base
- **Paralelizaci√≥n**: Evaluaci√≥n concurrente de modelos

### Compatibilidad
- **Formatos de salida**: ONNX, OpenVINO, PyTorch
- **Plataformas**: CPU, GPU (CUDA)
- **Integraci√≥n**: Hugging Face, Transformers

## üìÅ Estructura del Proyecto

```
train_embedding/
‚îú‚îÄ‚îÄ all-mini-base/          # Modelo base de referencia
‚îú‚îÄ‚îÄ models/                 # Modelos fine-tuneados
‚îÇ   ‚îú‚îÄ‚îÄ biobert/           # Variantes de BioBERT
‚îÇ   ‚îú‚îÄ‚îÄ sapbert-umls/      # SapBERT adaptado a UMLS
‚îÇ   ‚îú‚îÄ‚îÄ biomedical-roberta/ # RoBERTa biom√©dico
‚îÇ   ‚îî‚îÄ‚îÄ ...                # Otros modelos especializados
‚îú‚îÄ‚îÄ PNTs/                  # Documentos m√©dicos fuente
‚îú‚îÄ‚îÄ prepared_data/         # Datos procesados y chunks
‚îú‚îÄ‚îÄ resultados_comparacion/ # Reportes de evaluaci√≥n
‚îú‚îÄ‚îÄ resultados_ensemble_cat/ # Resultados de ensemble
‚îî‚îÄ‚îÄ scripts/               # Scripts de an√°lisis
```

## üõ†Ô∏è Uso del Sistema

### 1. Entrenamiento de Modelos
```bash
python cargador_models.py --model_type biobert --strategy conservative
```

### 2. Evaluaci√≥n Comparativa
```bash
python comparacion_modelos_multiple.py --base_model all-mini-base --models_folder ./models
```

### 3. Sistema de Ensemble
```bash
python comparar_esemble.py --config ensemble_config.json
```

## üìà Conclusiones y Hallazgos

### Principales Logros
1. **Mejora significativa**: Los modelos fine-tuneados superan al modelo base en un **31.3%** de precisi√≥n
2. **Especializaci√≥n efectiva**: Los modelos biom√©dicos muestran mejor rendimiento que los generales
3. **Multiling√ºismo**: Excelente adaptaci√≥n al catal√°n y espa√±ol m√©dico
4. **Escalabilidad**: Sistema capaz de evaluar 18+ modelos simult√°neamente

### Insights Clave
- **SapBERT-UMLS** es el modelo m√°s consistente para dominios m√©dicos
- **Biomedical-RoBERTa** ofrece el mejor rendimiento para espa√±ol
- **Estrategia conservadora** produce modelos m√°s estables
- **Ensemble** proporciona mejoras incrementales significativas

### Aplicaciones Pr√°cticas
- **B√∫squeda sem√°ntica** en bases de datos m√©dicas
- **Recuperaci√≥n de informaci√≥n** cl√≠nica
- **An√°lisis de similitud** entre documentos m√©dicos
- **Sistemas de recomendaci√≥n** para profesionales de la salud

## üîÆ Pr√≥ximos Pasos

1. **Expansi√≥n del dataset**: Incorporar m√°s documentos m√©dicos
2. **Optimizaci√≥n de hiperpar√°metros**: B√∫squeda autom√°tica de configuraciones √≥ptimas
3. **Integraci√≥n con sistemas cl√≠nicos**: Despliegue en entornos de producci√≥n
4. **Evaluaci√≥n en tareas espec√≠ficas**: Clasificaci√≥n, NER, QA m√©dica

## üìö Referencias

- **Modelos base**: Hugging Face Transformers
- **Dataset m√©dico**: Sistema de Salud P√∫blico de Catalu√±a
- **M√©tricas**: Est√°ndares de evaluaci√≥n de informaci√≥n retrieval
- **Framework**: PyTorch, Transformers, Sentence Transformers

## üë• Contribuciones

Este proyecto representa un esfuerzo colaborativo para mejorar la comprensi√≥n sem√°ntica de textos m√©dicos en lenguas minoritarias, contribuyendo al desarrollo de herramientas de IA m√°s inclusivas y efectivas para el sector sanitario.

---

*Proyecto desarrollado para el an√°lisis y optimizaci√≥n de embeddings biom√©dicos multiling√ºes*
