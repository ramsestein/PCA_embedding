# Re-Ranker H√≠brido Markov - Documentaci√≥n Completa de Experimentos

Un re-ranker h√≠brido avanzado que combina m√∫ltiples se√±ales para mejorar la recuperaci√≥n de informaci√≥n en sistemas RAG (Retrieval-Augmented Generation). Este README documenta la evoluci√≥n completa del proyecto a trav√©s de m√∫ltiples experimentos y optimizaciones.

## üöÄ Caracter√≠sticas del Sistema

- **Personalized PageRank (PPR)**: Random walk con reinicio sobre grafo de chunks
- **Query-Likelihood Model (QLM)**: Con suavizado Dirichlet y opci√≥n Jelinek-Mercer
- **Markov Random Field (MRF)**: Dependencias secuenciales con unigramas, bigramas ordenados y ventanas no ordenadas
- **Fusi√≥n Inteligente**: Mezcla lineal normalizada de todas las se√±ales
- **Configuraci√≥n Flexible**: Par√°metros ajustables para diferentes dominios

## üìã Requisitos

- Python 3.8+
- Dependencias listadas en `requirements.txt`

## üõ†Ô∏è Instalaci√≥n

```bash
# Clonar el repositorio
git clone <repository-url>
cd PCA_embedding

# Instalar dependencias
pip install -r requirements.txt

# Instalar en modo desarrollo (opcional)
pip install -e .
```

# üìä EXPERIMENTOS REALIZADOS

## üî§ **EXPERIMENTO 1: SOLO Detecci√≥n de Palabras Clave con Regex**

### **Objetivo**
Evaluar el rendimiento de la detecci√≥n l√©xica de palabras clave usando √∫nicamente expresiones regulares, sin combinaci√≥n con otros m√©todos.

### **Estrategia de Detecci√≥n**
- **M√©todo**: Solo detecci√≥n l√©xica con regex
- **Peso**: 100% para palabras clave
- **Sin combinaci√≥n**: No se mezclan con embeddings, MRF o QLM

### **Metodolog√≠a de Detecci√≥n de Palabras Clave**
1. **Extracci√≥n de t√©rminos**: Limpieza y tokenizaci√≥n de la query
2. **B√∫squeda con regex**: Patrones `\bpalabra\b` para coincidencias exactas
3. **An√°lisis de frecuencia**: Conteo y frecuencia de t√©rminos encontrados
4. **Puntuaci√≥n compuesta**: Combinaci√≥n de matches totales, t√©rminos √∫nicos y frecuencia promedio

### **Resultados Obtenidos**
| **M√©trica** | **Valor** | **Rendimiento** |
|-------------|-----------|-----------------|
| **Top1 Accuracy** | **35.4%** | ‚ö†Ô∏è **Medio** |
| **Top5 Accuracy** | **58.3%** | ‚ö†Ô∏è **Medio** |
| **MRR** | **0.4668** | ‚ö†Ô∏è **Medio** |
| **Queries Top1 correctas** | **17/48** | ‚ö†Ô∏è **Medio** |
| **Queries Top5 correctas** | **28/48** | ‚ö†Ô∏è **Medio** |

### **An√°lisis de Rendimiento**

#### **Queries Exitosas (Top1)**
- ‚úÖ "C√≥mo alto a un paciente paliativo con hospitalizaci√≥n a domicilio?" - Rank 1
- ‚úÖ "Que escalas debo pasar en la valoraci√≥n integral..." - Rank 1
- ‚úÖ "A quien debo hacer interconsulta en caso de paciente de onco gine?" - Rank 1
- ‚úÖ "Quien debe aprobar que se de una prestaci√≥n fuera del SISCAT..." - Rank 1
- ‚úÖ "Dame el link de acceso al CASCIPE" - Rank 1

#### **Queries con Rendimiento Bajo**
- ‚ùå "Quien gestiona el ingreso al centro de atenci√≥n intermedia..." - Rank 83
- ‚ùå "Con quien debo coordinar la medicaci√≥n a administrar..." - Rank 12
- ‚ùå "En paciente con DAI en radiolog√≠a, hay que llevar..." - Rank 19

---

## üîç **EXPERIMENTO 2: Evaluaci√≥n Inicial con All-Mini Base**

### **Objetivo**
Evaluar el rendimiento del re-ranker h√≠brido usando el modelo `all-mini-base` como baseline.

### **Configuraci√≥n**
- **Modelo**: `all-mini-base`
- **Dataset**: PNTs (48 queries m√©dicas)
- **Estrategias**: Solo embeddings, Solo MRF, MRF + Embeddings

### **Resultados**
| **Estrategia** | **Top1 Accuracy** | **Top5 Accuracy** | **Mejora vs Baseline** |
|----------------|-------------------|-------------------|-------------------------|
| **Solo Embeddings (Baseline)** | **33.3%** | **66.7%** | - |
| **Solo MRF** | **41.7%** | **68.8%** | Top1: +25.2% |
| **MRF + Embeddings** | **77.1%** | **85.4%** | Top1: +131.5% |

### **Conclusiones**
- **MRF + Embeddings** es significativamente superior al baseline
- **Solo MRF** mejora Top1 pero no Top5
- **H√≠brido** proporciona el mejor rendimiento general

---

## üéØ **EXPERIMENTO 3: Estrategias de Expansi√≥n Dimensional (25 Configuraciones)**

### **Objetivo**
Evaluar si a√±adir dimensiones artificiales mejora el rendimiento del modelo.

### **Metodolog√≠as Evaluadas**
- **Gaussiano Agresivo**: Ruido gaussiano controlado
- **Uniforme Agresivo**: Ruido uniforme controlado
- **Mixto**: Combinaci√≥n de ambos enfoques
- **Sem√°ntico Controlado**: Expansi√≥n basada en contenido

### **Resultados de Expansiones Dimensionales**
| **M√©todo** | **Dimensiones** | **Top1 Accuracy** | **MRR** | **Mejora vs Baseline** |
|------------|-----------------|-------------------|---------|-------------------------|
| **Gaussiano Muy Agresivo (100d)** | 484 | **42.7%** | **0.5346** | **+1.09%** |
| **Mixto Agresivo (150d)** | 534 | **42.7%** | **0.5341** | **+0.98%** |
| **Gaussiano Extremo (200d)** | 584 | **42.7%** | **0.5304** | **+0.29%** |
| **Baseline (384d)** | 384 | **41.7%** | **0.5289** | **+0.01%** |
| **Uniforme Muy Agresivo (100d)** | 484 | **41.7%** | **0.5283** | **-0.12%** |
| **Ultra: Sem√°ntico Controlado (300d)** | 684 | **12.5%** | **0.2463** | **-53.44%** |
| **Extreme: Adaptativo Extremo (900d)** | 1284 | **9.4%** | **0.2005** | **-62.10%** |

### **Conclusiones de Expansi√≥n Dimensional**
1. **Mejoras marginales**: Solo +1.09% en el mejor caso
2. **Degradaci√≥n con dimensionalidad extrema**: P√©rdidas de hasta -74.73%
3. **Gaussiano controlado**: Estrategia m√°s efectiva
4. **No recomendado**: Beneficio m√≠nimo vs complejidad a√±adida

---

## üîß **EXPERIMENTO 4: Reducci√≥n de Dimensionalidad Inteligente (PCA, t-SNE)**

### **Objetivo**
Evaluar si reducir dimensiones mantiene o mejora el rendimiento.

### **M√©todos Evaluados**
- **PCA**: 2D, 5D, 10D, 15D
- **t-SNE**: 2D optimizado
- **M√©tricas**: Varianza explicada, Silhouette score

### **Resultados de Reducci√≥n**
| **M√©todo** | **Dimensiones** | **Varianza Explicada** | **Silhouette Score** | **Distancia M√≠nima Promedio** |
|------------|-----------------|------------------------|---------------------|-------------------------------|
| **Original** | 384 | **100.0%** | **0.0671** | **0.7777** |
| **PCA 2D** | 2 | **22.49%** | **0.3270** | **2.9792** |
| **PCA 5D** | 5 | **44.34%** | **0.2387** | **8.2680** |
| **PCA 10D** | 10 | **68.75%** | **0.1317** | **14.0413** |
| **PCA 15D** | 15 | **85.52%** | **0.0558** | **18.3746** |
| **t-SNE 2D** | 2 | **N/A** | **0.2643** | **6.5547** |

### **Conclusiones de Reducci√≥n**
1. **PCA 2D**: Mejor discriminaci√≥n (Silhouette: 0.3270)
2. **P√©rdida de informaci√≥n**: Varianza explicada decrece significativamente
3. **t-SNE**: Alternativa para visualizaci√≥n 2D
4. **No recomendado**: P√©rdida de rendimiento vs ganancia de eficiencia

---

## üìä **EXPERIMENTO 5: Augmentaci√≥n Sem√°ntica (Variaciones de Embeddings)**

### **Objetivo**
Evaluar si generar variaciones sem√°nticas de los embeddings mejora el rendimiento.

### **Resultados**
| **M√©todo** | **Top1 Accuracy** | **MRR** | **Mejora vs Baseline** |
|------------|-------------------|---------|-------------------------|
| **Baseline (Original)** | **41.7%** | **0.5289** | - |
| **Augmentaci√≥n Sem√°ntica** | **41.7%** | **0.4886** | **-7.62%** |

### **Conclusiones**
- **No mejora**: Degradaci√≥n del 7.62% en MRR
- **Misma precisi√≥n**: Top1 accuracy id√©ntica
- **No recomendado**: P√©rdida de rendimiento sin beneficio

---

## üî¨ **EXPERIMENTO 6: Experimentos con Diferentes Tipos de Ruido**

### **Objetivo**
Evaluar el impacto de diferentes tipos de ruido (gaussiano, uniforme, exponencial) en el rendimiento.

### **Configuraciones Evaluadas**
- **12 experimentos** con diferentes tipos y escalas de ruido
- **Dimensiones adicionales**: 50 por experimento
- **Tipos**: Gaussiano, Uniforme, Exponencial
- **Escalas**: 0.05, 0.10, 0.15, 0.20

### **Resultados por Tipo de Ruido**
| **Tipo** | **Mejor Escala** | **Ratio Varianza** | **Control de Ruido** |
|----------|-------------------|---------------------|----------------------|
| **Gaussiano** | 0.20 | 0.4712 | ‚úÖ Excelente |
| **Uniforme** | 0.20 | 0.4674 | ‚úÖ Excelente |
| **Exponencial** | 0.20 | 0.4798 | ‚úÖ Bueno |

### **Mejor Configuraci√≥n**
- **Tipo**: Uniforme Muy Agresivo
- **Escala**: 0.20
- **Ratio de varianza**: 0.4674
- **Control**: Excelente

---

## üöÄ **EXPERIMENTO 7: Expansiones Ultra-Inteligentes**

### **Objetivo**
Implementar estrategias ultra-inteligentes para alcanzar Top-1 del 100%.

### **Estrategias Implementadas**
1. **Sem√°ntico Controlado (300d)**: Control sem√°ntico con 300 dimensiones
2. **Progresivo Inteligente (400d)**: Expansi√≥n progresiva inteligente
3. **Espec√≠fico por Documento (500d)**: Diferenciaci√≥n espec√≠fica por documento
4. **Balance Sem√°ntico (600d)**: Equilibrio entre sem√°ntica y diferenciaci√≥n
5. **Adaptativo por Clusters (700d)**: Adaptaci√≥n basada en clusters
6. **Secuencial Inteligente (800d)**: Secuencia inteligente de expansi√≥n
7. **H√≠brido Ultra-Controlado (900d)**: Control h√≠brido ultra-avanzado

### **Resultados de Expansiones Ultra**
| **Estrategia** | **Dimensiones** | **Separaci√≥n** | **Preservaci√≥n Sem√°ntica** | **Top1 Promedio** |
|----------------|-----------------|----------------|----------------------------|-------------------|
| **Sem√°ntico Controlado** | 684 | 0.8878 | 0.1435 | **25.0%** |
| **Progresivo Inteligente** | 784 | 0.9133 | 0.0342 | **20.8%** |
| **Espec√≠fico por Documento** | 884 | 0.9020 | 0.0111 | **20.8%** |
| **Balance Sem√°ntico** | 984 | 0.9279 | 0.0175 | **20.8%** |
| **Adaptativo por Clusters** | 1084 | 0.6180 | -0.0005 | **6.3%** |
| **Secuencial Inteligente** | 1184 | 0.9188 | 0.0106 | **20.8%** |
| **H√≠brido Ultra-Controlado** | 1284 | 0.9281 | 0.0302 | **4.2%** |

### **Conclusiones**
- **Mejor estrategia**: Sem√°ntico Controlado (300d) con 25.0% Top1
- **Degradaci√≥n progresiva**: Mayor dimensionalidad = peor rendimiento
- **No se alcanza Top-1 100%**: Las expansiones ultra degradan el rendimiento

---

## üåü **EXPERIMENTO 8: Expansiones Extremas Masivas**

### **Objetivo**
Evaluar expansiones masivas de hasta 1000+ dimensiones para maximizar diferenciaci√≥n.

### **Estrategias Extremas Evaluadas**
1. **Extremo Uniforme Ultra Masivo (1000d)**: 1384 dimensiones totales
2. **Extremo Gaussiano Ultra Masivo (1000d)**: 1384 dimensiones totales
3. **Extremo Secuencial (800d)**: 1184 dimensiones totales
4. **Extremo H√≠brido Complejo (750d)**: 1134 dimensiones totales
5. **Extremo Basado en Clusters (600d)**: 984 dimensiones totales

### **Resultados de Expansiones Extremas**
| **Estrategia** | **Dimensiones** | **Top1 Accuracy** | **MRR** | **Degradaci√≥n vs Baseline** |
|----------------|-----------------|-------------------|---------|----------------------------|
| **Extremo Uniforme Ultra Masivo** | 1384 | **7.3%** | **0.1980** | **-62.57%** |
| **Extremo Gaussiano Ultra Masivo** | 1384 | **6.3%** | **0.1704** | **-67.78%** |
| **Extremo Secuencial** | 1184 | **4.2%** | **0.1556** | **-70.59%** |
| **Extremo H√≠brido Complejo** | 1134 | **5.2%** | **0.1489** | **-71.85%** |
| **Extremo Basado en Clusters** | 984 | **6.3%** | **0.1849** | **-65.04%** |

### **Conclusiones**
- **Degradaci√≥n masiva**: P√©rdidas de hasta -71.85% en MRR
- **No recomendado**: Las expansiones extremas destruyen el rendimiento
- **L√≠mite identificado**: M√°ximo 200 dimensiones adicionales para mantener rendimiento

---

## üß¨ **EXPERIMENTO 9: Fine-Tuning de Modelos Biom√©dicos y Sistema de Ensemble**

### **Objetivo**
Desarrollar y evaluar modelos de embeddings especializados en el dominio biom√©dico mediante fine-tuning, y crear un sistema de ensemble para mejorar significativamente el rendimiento en tareas de recuperaci√≥n de informaci√≥n m√©dica.

### **Metodolog√≠a de Fine-Tuning**

#### **Preparaci√≥n de Datos**
- **Dataset**: 24 documentos m√©dicos del sistema sanitario catal√°n
- **Chunks generados**: 194 chunks con longitud promedio de 244 palabras
- **Pares de entrenamiento**: 1,344 pares con distribuci√≥n:
  - **Semi-hard**: 873 pares (65%)
  - **Hard**: 315 pares (23%)
  - **Easy**: 156 pares (12%)

#### **Modelos Base Evaluados**
- **BioBERT**: Variantes v1.1 y v1.2
- **BioClinicalBERT**: Especializado en textos cl√≠nicos
- **SapBERT**: Adaptado para UMLS y PubMed
- **PubMedBERT**: Versiones MS y MS-MARCO
- **DeBERTa-v3**: Configuraciones conservadora y agresiva
- **Biomedical-RoBERTa**: Especializado en espa√±ol
- **RoBERTa-Catalan**: Modelo base en catal√°n

#### **Estrategias de Entrenamiento**
- **Estrategia conservadora**: Fine-tuning gradual con learning rates bajos
- **Estrategia agresiva**: Fine-tuning intensivo con learning rates altos
- **Early stopping**: Parada temprana basada en p√©rdida de validaci√≥n
- **Checkpoints m√∫ltiples**: Guardado de modelos en diferentes √©pocas

### **Resultados del Fine-Tuning**

#### **Rendimiento del Modelo Base**
| **M√©trica** | **Valor** | **Rendimiento** |
|-------------|-----------|-----------------|
| **Accuracy@1** | **31.2%** | ‚ùå **Bajo** |
| **Accuracy@5** | **50.0%** | ‚ùå **Bajo** |
| **MRR** | **0.389** | ‚ùå **Bajo** |
| **Similitud promedio** | **53.96%** | ‚ùå **Bajo** |

#### **Top 5 Modelos Mejorados**
| **#** | **Modelo** | **Acc@1** | **Mejora** | **Acc@5** | **MRR** | **Velocidad** |
|-------|------------|-----------|------------|-----------|---------|---------------|
| **1** | **SapBERT-UMLS** | **64.6%** | **+33.4pp** | **77.1%** | **0.692** | **0.0059s** |
| **2** | **Biomedical-RoBERTa** | **62.5%** | **+31.3pp** | **66.7%** | **0.642** | **0.0055s** |
| **3** | **SapBERT-UMLS** | **62.5%** | **+31.3pp** | **75.0%** | **0.674** | **0.0055s** |
| **4** | **SapBERT-UMLS** | **62.5%** | **+31.3pp** | **75.0%** | **0.678** | **0.0050s** |
| **5** | **SapBERT-UMLS** | **62.5%** | **+31.3pp** | **77.1%** | **0.677** | **0.0052s** |

#### **Mejoras por Categor√≠a de Modelo**
- **Modelos biom√©dicos especializados**: +25-30pp en Accuracy@1
- **Modelos multiling√ºes**: +20-25pp en Accuracy@1
- **Modelos generales fine-tuneados**: +15-20pp en Accuracy@1

### **Sistema de Ensemble**

#### **Configuraci√≥n del Ensemble**
- **Componentes principales**: PubMedBERT-Marco (57.1%) + SapBERT-UMLS (42.9%)
- **M√©todo de combinaci√≥n**: Promedio ponderado de embeddings
- **Optimizaci√≥n**: Pesos ajustados para maximizar diversidad y rendimiento

#### **Resultados del Ensemble**
| **M√©trica** | **Modelo Base** | **Ensemble** | **Mejora** |
|-------------|-----------------|--------------|------------|
| **Accuracy@1** | **39.6%** | **77.1%** | **+37.5pp** |
| **Accuracy@5** | **64.6%** | **91.7%** | **+27.1pp** |
| **MRR** | **0.492** | **0.823** | **+0.331** |
| **MAP** | **0.492** | **0.823** | **+0.331** |
| **NDCG@5** | **0.531** | **0.846** | **+0.315** |

#### **An√°lisis de Velocidad**
- **Modelo base**: 0.0029s/query
- **Ensemble**: 0.0088s/query
- **Factor**: 3.04x m√°s lento (trade-off rendimiento vs velocidad)

### **An√°lisis Comparativo con Estrategias Anteriores**
| **Estrategia** | **Top1 Accuracy** | **Top5 Accuracy** | **Rendimiento** |
|----------------|-------------------|-------------------|-----------------|
| **Solo Embeddings (SAPBERT)** | **60.4%** | **79.2%** | ü•á **MEJOR** |
| **MRF + Embeddings (Pesos Adaptativos)** | **72.9%** | **89.6%** | ü•á **MEJOR** |
| **MRF + Embeddings (Ensemble)** | **77.1%** | **85.4%** | ü•á **MEJOR** |
| **Fine-Tuning + Ensemble** | **77.1%** | **91.7%** | üèÜ **EXCELENTE** |

### **Caracter√≠sticas T√©cnicas Implementadas**

#### **Optimizaciones del Sistema**
- **Pooling adaptativo**: Selecci√≥n autom√°tica de estrategia √≥ptima
- **Batch processing**: Procesamiento eficiente de m√∫ltiples modelos
- **Caching de embeddings**: Reutilizaci√≥n de embeddings base
- **Paralelizaci√≥n**: Evaluaci√≥n concurrente de modelos

#### **Compatibilidad y Formatos**
- **Formatos de salida**: ONNX, OpenVINO, PyTorch
- **Plataformas**: CPU, GPU (CUDA)
- **Integraci√≥n**: Hugging Face, Transformers

### **Problemas Identificados**
1. **Overfitting**: Algunos modelos muestran signos de sobreajuste
2. **Velocidad**: El ensemble es 3x m√°s lento que modelos individuales
3. **Memoria**: Requiere m√°s recursos computacionales
4. **Complejidad**: Mayor dificultad de mantenimiento y despliegue

### **Fortalezas Identificadas**
1. **Mejora significativa**: +37.5pp en Accuracy@1 sobre el modelo base
2. **Especializaci√≥n efectiva**: Modelos biom√©dicos superan a los generales
3. **Multiling√ºismo**: Excelente adaptaci√≥n al catal√°n y espa√±ol m√©dico
4. **Escalabilidad**: Sistema capaz de evaluar 18+ modelos simult√°neamente
5. **Robustez**: El ensemble reduce la variabilidad individual de modelos

### **Recomendaciones de Uso**
1. **Para m√°xima precisi√≥n**: Usar el ensemble completo
2. **Para balance rendimiento-velocidad**: Usar SapBERT-UMLS individual
3. **Para entornos con recursos limitados**: Usar Biomedical-RoBERTa
4. **Para producci√≥n**: Considerar el trade-off entre precisi√≥n y latencia

### **Lecciones Aprendidas**
1. **El fine-tuning especializado mejora significativamente el rendimiento biom√©dico**
2. **Los modelos m√©dicos especializados superan consistentemente a los generales**
3. **El ensemble proporciona mejoras incrementales significativas**
4. **La estrategia conservadora produce modelos m√°s estables**
5. **El multiling√ºismo es crucial para dominios m√©dicos regionales**

### **Aplicaciones Pr√°cticas Identificadas**
- **B√∫squeda sem√°ntica** en bases de datos m√©dicas
- **Recuperaci√≥n de informaci√≥n** cl√≠nica
- **An√°lisis de similitud** entre documentos m√©dicos
- **Sistemas de recomendaci√≥n** para profesionales de la salud
- **Clasificaci√≥n autom√°tica** de textos m√©dicos

---

## üî¨ **EXPERIMENTO 10: Benchmark de Modelos SAPBERT-UMLS**

### **Objetivo**
Evaluar todos los modelos SAPBERT-UMLS disponibles para identificar el mejor.

### **Metodolog√≠a**
- **Modelos evaluados**: 10 modelos (model-0_0000 a model-0_4735)
- **Dataset**: PNTs (48 queries)
- **M√©trica**: Top1 y Top5 accuracy

### **Resultados del Benchmark**
| **Modelo** | **Top1 Accuracy** | **Top5 Accuracy** | **Top1 Correct** | **Top5 Correct** |
|------------|-------------------|-------------------|-------------------|-------------------|
| **model-0_0029** | **70.8%** | **83.3%** | **34/48** | **40/48** |
| model-0_0000 | 68.8% | 81.3% | 33/48 | 39/48 |
| model-0_0000_1 | 68.8% | 83.3% | 33/48 | 40/48 |
| model-0_0001 | 66.7% | 81.3% | 32/48 | 39/48 |
| model-0_0002 | 66.7% | 83.3% | 32/48 | 40/48 |
| model-0_0009 | 66.7% | 81.3% | 32/48 | 39/48 |
| model-0_0183 | 68.8% | 83.3% | 33/48 | 40/48 |
| model-0_0853 | 64.6% | 85.4% | 31/48 | 41/48 |
| model-0_2688 | 60.4% | 77.1% | 29/48 | 37/48 |
| model-0_4735 | 62.5% | 85.4% | 30/48 | 41/48 |

### **Selecci√≥n del Modelo**
- **Modelo seleccionado**: `model-0_0029`
- **Raz√≥n**: Mejor Top1 accuracy (70.8%)
- **Acci√≥n**: Eliminaci√≥n de todos los dem√°s modelos

---

## üìà **EXPERIMENTO 11: Benchmark Completo con SAPBERT √ìptimo**

### **Objetivo**
Re-ejecutar todas las estrategias h√≠bridas usando `model-0_0029` en lugar de `all-mini-base`.

### **Resultados Comparativos**

#### **Baseline (SAPBERT vs All-Mini)**
| **Modelo** | **Top1 Accuracy** | **Top5 Accuracy** | **Mejora vs All-Mini** |
|------------|-------------------|-------------------|-------------------------|
| **All-Mini** | **37.5%** | **66.7%** | - |
| **SAPBERT** | **70.8%** | **83.3%** | Top1: +88.8%, Top5: +24.9% |

#### **Estrategias H√≠bridas con SAPBERT**
| **Estrategia** | **Top1 Accuracy** | **Top5 Accuracy** | **Mejora vs Baseline** |
|----------------|-------------------|-------------------|-------------------------|
| **Solo Embeddings (SAPBERT)** | **60.4%** | **79.2%** | - |
| **Solo MRF** | **41.7%** | **68.8%** | Top1: -31.0%, Top5: -13.2% |
| **MRF + Embeddings** | **77.1%** | **85.4%** | Top1: +27.6%, Top5: +7.9% |
| **MRF + Embeddings (Pesos Adaptativos)** | **72.9%** | **89.6%** | Top1: +20.7%, Top5: +13.2% |
| **MRF + Embeddings (Ventanas Optimizadas)** | **72.9%** | **89.6%** | Top1: +20.7%, Top5: +13.2% |
| **MRF + Embeddings (Normalizaci√≥n Inteligente)** | **60.4%** | **87.5%** | Top1: +0.0%, Top5: +10.5% |
| **MRF + Embeddings (Ensemble)** | **77.1%** | **85.4%** | Top1: +27.6%, Top5: +7.9% |
| **MRF + Embeddings (Aprendizaje Adaptativo)** | **75.0%** | **83.3%** | Top1: +24.1%, Top5: +5.3% |

### **Conclusiones Clave**
1. **SAPBERT** supera significativamente a **All-Mini** (+88.8% Top1)
2. **Pesos Adaptativos** proporcionan el **mejor Top5** (89.6%)
3. **Ensemble MRF** proporciona el **mejor Top1** (77.1%)
4. **Normalizaci√≥n Inteligente** degrada Top1 sin beneficio claro

---

## üîç **EXPERIMENTO 12: An√°lisis de Solapamiento entre Modelos**

### **Objetivo**
Calcular el solapamiento de clasificaci√≥n correcta entre SAPBERT y All-Mini para entender la complementariedad.

### **Metodolog√≠a**
- **Dataset**: 48 queries m√©dicas
- **An√°lisis**: Queries √∫nicas vs comunes entre modelos
- **M√©tricas**: Solapamiento Top1 y Top5

### **Resultados del Solapamiento**

#### **TOP1 ACCURACY**
| **Categor√≠a** | **Cantidad** | **Porcentaje** | **Descripci√≥n** |
|---------------|---------------|----------------|-----------------|
| **Solapamiento** | 17/48 | **35.4%** | Queries que AMBOS modelos resuelven correctamente |
| **Solo SAPBERT** | 17/48 | **35.4%** | Queries que SOLO SAPBERT resuelve correctamente |
| **Solo All-Mini** | 1/48 | **2.1%** | Queries que SOLO All-Mini resuelve correctamente |
| **Ninguno** | 13/48 | **27.1%** | Queries que NING√öN modelo resuelve correctamente |

#### **TOP5 ACCURACY**
| **Categor√≠a** | **Cantidad** | **Porcentaje** | **Descripci√≥n** |
|---------------|---------------|----------------|-----------------|
| **Solapamiento** | 1/48 | **2.1%** | Queries en Top5 que AMBOS modelos resuelven |
| **Solo SAPBERT** | 5/48 | **10.4%** | Queries en Top5 que SOLO SAPBERT resuelve |
| **Solo All-Mini** | 10/48 | **20.8%** | Queries en Top5 que SOLO All-Mini resuelve |

### **Conclusiones del Solapamiento**
1. **Solapamiento bajo**: Solo 35.4% de queries resueltas por ambos modelos
2. **Dominancia de SAPBERT**: Resuelve 16 queries m√°s √∫nicamente
3. **Complementariedad limitada**: Solo 1 query √∫nica de All-Mini
4. **Reemplazo eficiente**: SAPBERT cubre 95.8% de las queries de All-Mini

---

## üîç **EXPERIMENTO 13: An√°lisis de Solapamiento entre Modelos (SAPBERT vs All-Mini)**

### **Objetivo**
Calcular el solapamiento de clasificaci√≥n correcta entre SAPBERT y All-Mini para entender la complementariedad.

### **Metodolog√≠a**
- **Dataset**: 48 queries m√©dicas
- **An√°lisis**: Queries √∫nicas vs comunes entre modelos
- **M√©tricas**: Solapamiento Top1 y Top5

### **Resultados del Solapamiento**

#### **TOP1 ACCURACY**
| **Categor√≠a** | **Cantidad** | **Porcentaje** | **Descripci√≥n** |
|---------------|---------------|----------------|-----------------|
| **Solapamiento** | 17/48 | **35.4%** | Queries que AMBOS modelos resuelven correctamente |
| **Solo SAPBERT** | 17/48 | **35.4%** | Queries que SOLO SAPBERT resuelve correctamente |
| **Solo All-Mini** | 1/48 | **2.1%** | Queries que SOLO All-Mini resuelve correctamente |
| **Ninguno** | 13/48 | **27.1%** | Queries que NING√öN modelo resuelve correctamente |

#### **TOP5 ACCURACY**
| **Categor√≠a** | **Cantidad** | **Porcentaje** | **Descripci√≥n** |
|---------------|---------------|----------------|-----------------|
| **Solapamiento** | 1/48 | **2.1%** | Queries en Top5 que AMBOS modelos resuelven |
| **Solo SAPBERT** | 5/48 | **10.4%** | Queries en Top5 que SOLO SAPBERT resuelve |
| **Solo All-Mini** | 10/48 | **20.8%** | Queries en Top5 que SOLO All-Mini resuelve |

### **Conclusiones del Solapamiento**
1. **Solapamiento bajo**: Solo 35.4% de queries resueltas por ambos modelos
2. **Dominancia de SAPBERT**: Resuelve 16 queries m√°s √∫nicamente
3. **Complementariedad limitada**: Solo 1 query √∫nica de All-Mini
4. **Reemplazo eficiente**: SAPBERT cubre 95.8% de las queries de All-Mini

---

## üß™ **EXPERIMENTO 14: Implementaci√≥n Base del Re-Ranker H√≠brido**

### **Objetivo**
Implementar el sistema base con PPR, QLM, MRF y fusi√≥n de se√±ales.

### **Resultados**
- **Tests**: 99/99 tests pasando (100% de √©xito)
- **Funcionalidad**: Sistema completamente operativo
- **CLI**: Funcional para re-ranking y evaluaci√≥n

---

## üöÄ **EXPERIMENTO 15: Implementaci√≥n de Optimizaciones Incrementales**

### **Objetivo**
Aplicar mejoras una por una para evaluar su impacto individual.

### **Mejora 1: Pesos Adaptativos**
- **L√≥gica**: Ajustar pesos MRF vs Embeddings seg√∫n longitud de query
- **Resultado**: Top1: 72.9%, Top5: 89.6%
- **Mejora**: Top1: +20.7%, Top5: +13.2%

### **Mejora 2: Ventanas Optimizadas**
- **L√≥gica**: Optimizar tama√±os de ventana para bigramas no ordenados
- **Resultado**: Top1: 72.9%, Top5: 89.6%
- **Mejora**: Igual a Mejora 1 (no aporta valor adicional)

### **Mejora 3: Normalizaci√≥n Inteligente**
- **L√≥gica**: Normalizaci√≥n robusta usando percentiles y escalado adaptativo
- **Resultado**: Top1: 60.4%, Top5: 87.5%
- **Mejora**: Top1: +0.0%, Top5: +10.5% (degradaci√≥n en Top1)

### **Mejora 4: Ensemble MRF**
- **L√≥gica**: Combinar m√∫ltiples configuraciones MRF con pesos adaptativos
- **Resultado**: Top1: 77.1%, Top5: 85.4%
- **Mejora**: Top1: +27.6%, Top5: +7.9%

### **Mejora 6: Sistema de Aprendizaje Adaptativo**
- **L√≥gica**: Feedback system que aprende de queries anteriores
- **Resultado**: Top1: 75.0%, Top5: 83.3%
- **Mejora**: Top1: +24.1%, Top5: +5.3%

---

## üî§ **EXPERIMENTO 16: SAPBERT + Markov + Detecci√≥n de Palabras Clave con Regex**

### **Objetivo**
Combinar embeddings m√©dicos especializados (SAPBERT) con Markov Random Field y detecci√≥n l√©xica de palabras clave usando expresiones regulares.

### **Estrategia de Hibridaci√≥n**
- **SAPBERT (40%)**: Embeddings m√©dicos especializados
- **MRF (30%)**: Dependencias secuenciales y bigramas
- **QLM (20%)**: Query-Likelihood Model con suavizado Dirichlet
- **Palabras Clave (10%)**: Detecci√≥n l√©xica con regex

### **Metodolog√≠a de Detecci√≥n de Palabras Clave**
1. **Extracci√≥n de t√©rminos**: Limpieza y tokenizaci√≥n de la query
2. **B√∫squeda con regex**: Patrones `\bpalabra\b` para coincidencias exactas
3. **An√°lisis de frecuencia**: Conteo y frecuencia de t√©rminos encontrados
4. **Puntuaci√≥n compuesta**: Combinaci√≥n de matches totales, t√©rminos √∫nicos y frecuencia promedio

### **Resultados Obtenidos**
| **M√©trica** | **Valor** | **Rendimiento** |
|-------------|-----------|-----------------|
| **Top1 Accuracy** | **27.1%** | ‚ùå **Bajo** |
| **Top5 Accuracy** | **37.5%** | ‚ùå **Bajo** |
| **MRR** | **0.3263** | ‚ùå **Bajo** |
| **Queries Top1 correctas** | **13/48** | ‚ùå **Bajo** |
| **Queries Top5 correctas** | **18/48** | ‚ùå **Bajo** |

### **An√°lisis de Rendimiento**

#### **Queries Exitosas (Top1)**
- ‚úÖ "C√≥mo alto a un paciente paliativo con hospitalizaci√≥n a domicilio?" - Rank 1
- ‚úÖ "Que escalas debo pasar en la valoraci√≥n integral..." - Rank 2
- ‚úÖ "A quien debo hacer interconsulta en caso de paciente de onco gine?" - Rank 1
- ‚úÖ "Quien debe aprobar que se de una prestaci√≥n fuera del SISCAT..." - Rank 1
- ‚úÖ "Dame el link de acceso al CASCIPE" - Rank 1

#### **Queries con Rendimiento Bajo**
- ‚ùå "Quien gestiona el ingreso al centro de atenci√≥n intermedia..." - Rank 83
- ‚ùå "Con quien debo coordinar la medicaci√≥n a administrar..." - Rank 12
- ‚ùå "En paciente con DAI en radiolog√≠a, hay que llevar..." - Rank 19

### **Comparaci√≥n con Estrategias Anteriores**
| **Estrategia** | **Top1 Accuracy** | **Top5 Accuracy** | **Rendimiento** |
|----------------|-------------------|-------------------|-----------------|
| **Solo Embeddings (SAPBERT)** | **60.4%** | **79.2%** | ü•á **MEJOR** |
| **MRF + Embeddings (Pesos Adaptativos)** | **72.9%** | **89.6%** | ü•á **MEJOR** |
| **MRF + Embeddings (Ensemble)** | **77.1%** | **85.4%** | ü•á **MEJOR** |
| **SAPBERT + Markov + Palabras Clave** | **27.1%** | **37.5%** | ‚ùå **PEOR** |

### **Problemas Identificados**
1. **Peso de palabras clave muy bajo (10%)**: La detecci√≥n l√©xica tiene poco impacto
2. **Normalizaci√≥n agresiva**: Las puntuaciones se normalizan demasiado, perdiendo discriminaci√≥n
3. **Combinaci√≥n de se√±ales**: Las diferentes escalas no se combinan √≥ptimamente
4. **P√©rdida de informaci√≥n sem√°ntica**: El enfoque l√©xico puede interferir con la sem√°ntica

### **Fortalezas Identificadas**
1. **Detecci√≥n precisa de t√©rminos m√©dicos**: Las palabras clave se detectan correctamente
2. **Integraci√≥n de m√∫ltiples se√±ales**: El sistema combina 4 tipos de informaci√≥n
3. **Flexibilidad de pesos**: Los pesos se pueden ajustar f√°cilmente
4. **An√°lisis detallado**: Proporciona informaci√≥n granular sobre cada componente

### **Recomendaciones de Mejora**
1. **Aumentar peso de palabras clave**: De 10% a 25-30%
2. **Reducir peso de embeddings**: De 40% a 25-30%
3. **Ajustar normalizaci√≥n**: Usar min-max en lugar de z-score
4. **Balancear se√±ales**: MRF 30%, QLM 20%, Keywords 25%, Embeddings 25%

### **Lecciones Aprendidas**
1. **La combinaci√≥n de se√±ales requiere normalizaci√≥n cuidadosa**
2. **Los pesos deben reflejar la importancia relativa de cada se√±al**
3. **La detecci√≥n l√©xica puede complementar pero no reemplazar la sem√°ntica**
4. **La hibridaci√≥n exitosa requiere balance y sintonizaci√≥n fina**

---

# üèÜ **RESUMEN FINAL DE EXPERIMENTOS**

---

## **Resumen de Todos los Experimentos Realizados**

### **üìä Total de Experimentos: 16**
1. ‚úÖ **SOLO Detecci√≥n de Palabras Clave con Regex**
2. ‚úÖ **Evaluaci√≥n Inicial con All-Mini Base**
3. ‚úÖ **Estrategias de Expansi√≥n Dimensional (25 configuraciones)**
4. ‚úÖ **Reducci√≥n de Dimensionalidad Inteligente (PCA, t-SNE)**
5. ‚úÖ **Augmentaci√≥n Sem√°ntica**
6. ‚úÖ **Experimentaci√≥n con Diferentes Tipos de Ruido (12 configuraciones)**
7. ‚úÖ **Expansiones Ultra-Inteligentes (7 estrategias)**
8. ‚úÖ **Expansiones Extremas Masivas (5 estrategias)**
9. ‚úÖ **Fine-Tuning de Modelos Biom√©dicos y Sistema de Ensemble**
10. ‚úÖ **Benchmark de Modelos SAPBERT-UMLS (10 modelos)**
11. ‚úÖ **Benchmark Completo con SAPBERT √ìptimo**
12. ‚úÖ **An√°lisis de Solapamiento entre Modelos**
13. ‚úÖ **An√°lisis de Solapamiento entre Modelos (SAPBERT vs All-Mini)**
14. ‚úÖ **Implementaci√≥n Base del Re-Ranker H√≠brido**
15. ‚úÖ **Implementaci√≥n de Optimizaciones Incrementales (5 mejoras)**
16. ‚úÖ **SAPBERT + Markov + Detecci√≥n de Palabras Clave con Regex**

## **Mejores Estrategias Identificadas**

### **ü•á TOP1 ACCURACY**
- **Estrategia**: MRF + Embeddings (Ensemble)
- **Rendimiento**: 77.1%
- **Modelo**: SAPBERT-UMLS (model-0_0029)
- **Experimento**: EXPERIMENTO 11

### **ü•á TOP5 ACCURACY**
- **Estrategia**: Fine-Tuning + Ensemble (PubMedBERT-Marco + SapBERT-UMLS)
- **Rendimiento**: 91.7%
- **Modelo**: Ensemble de modelos biom√©dicos fine-tuneados
- **Experimento**: EXPERIMENTO 9

### **ü•á MEJOR MODELO BASE**
- **Modelo**: SAPBERT-UMLS (model-0_0029)
- **Rendimiento**: 70.8% Top1, 83.3% Top5
- **Ventaja**: +88.8% vs All-Mini en Top1
- **Experimento**: EXPERIMENTO 10

### **ü•á MEJOR EXPANSI√ìN DIMENSIONAL**
- **Estrategia**: Gaussiano Muy Agresivo (100d)
- **Mejora**: +1.09% en MRR
- **Dimensiones**: 484 totales
- **Tipo**: Ruido gaussiano controlado
- **Experimento**: EXPERIMENTO 3

## **Estrategias No Recomendadas**

1. **Expansi√≥n Dimensional Extrema**: Degradaci√≥n masiva (-71.85% MRR)
2. **Reducci√≥n Dimensional**: P√©rdida significativa de informaci√≥n
3. **Augmentaci√≥n Sem√°ntica**: Degradaci√≥n del 7.62%
4. **Normalizaci√≥n Inteligente**: Degradaci√≥n en Top1
5. **Expansiones Ultra-Inteligentes**: Degradaci√≥n progresiva con dimensionalidad
6. **Expansiones Masivas**: Destruyen el rendimiento del modelo
7. **Hibridaci√≥n l√©xico-sem√°ntica desbalanceada**: Peso insuficiente para palabras clave (10%)

## **L√≠mites Identificados**

- **M√°ximo dimensiones adicionales**: 200 para mantener rendimiento
- **Mejor tipo de ruido**: Gaussiano controlado
- **Mejor escala de ruido**: 0.20 para diferenciaci√≥n √≥ptima
- **Ratio de varianza √≥ptimo**: 0.80-0.85 para preservaci√≥n sem√°ntica

## **Recomendaci√≥n de Producci√≥n**

### **ü•á ESTRATEGIA PRINCIPAL: "Fine-Tuning + Ensemble"**
**Usar el ensemble de PubMedBERT-Marco + SapBERT-UMLS fine-tuneados** porque:
- ‚úÖ **Mejor Top1** (77.1%) - m√°xima precisi√≥n
- ‚úÖ **Mejor Top5** (91.7%) - m√°xima cobertura
- ‚úÖ **Mejora m√°xima** (+37.5pp sobre modelo base)
- ‚úÖ **Especializaci√≥n biom√©dica** - dominio espec√≠fico optimizado
- ‚úÖ **Multiling√ºe** - catal√°n y espa√±ol
- ‚úÖ **Validado** - a trav√©s de 16 experimentos exhaustivos
- ‚úÖ **Experimento**: EXPERIMENTO 9

### **ü•à ESTRATEGIA ALTERNATIVA: "MRF + Embeddings (Pesos Adaptativos)"**
**Usar con SAPBERT-UMLS (model-0_0029)** para:
- ‚úÖ **Balance rendimiento-velocidad** - Top5: 89.6%, Top1: 72.9%
- ‚úÖ **Simplicidad** - solo una optimizaci√≥n activa
- ‚úÖ **Estabilidad** - no degrada el rendimiento
- ‚úÖ **Recursos limitados** - menor complejidad computacional
- ‚úÖ **Experimento**: EXPERIMENTO 15

---

# ü§ù **Contribuciones**

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

# üìÑ **Licencia**

Este proyecto est√° bajo la Licencia MIT. Ver `LICENSE` para m√°s detalles.

---

# üìà **ESTAD√çSTICAS GENERALES DEL PROYECTO**

## **Resumen de Actividad**
- **Total de experimentos realizados**: 16
- **Total de configuraciones evaluadas**: 100+
- **Total de modelos probados**: 18+ (10 SAPBERT + 1 All-Mini + 1 Baseline + 6+ biom√©dicos)
- **Total de estrategias h√≠bridas**: 11
- **Total de tipos de ruido evaluados**: 3 (Gaussiano, Uniforme, Exponencial)
- **Total de expansiones dimensionales**: 25 configuraciones
- **Total de archivos de resultados generados**: 50+
- **Tiempo total de experimentaci√≥n**: M√∫ltiples sesiones de desarrollo

## **M√©tricas de Rendimiento por Categor√≠a**

### **üèÜ Mejores Resultados por Categor√≠a**
- **Top1 Accuracy**: 77.1% (Fine-Tuning + Ensemble)
- **Top5 Accuracy**: 91.7% (Fine-Tuning + Ensemble)
- **Mejora vs Baseline**: +131.5% (MRF + Embeddings vs Solo Embeddings)
- **Mejora por Fine-Tuning**: +37.5pp (Ensemble vs Modelo Base)
- **Mejora por Expansi√≥n Dimensional**: +1.09% (Gaussiano Muy Agresivo)
- **Mejor Modelo Base**: SAPBERT-UMLS (model-0_0029) con 70.8% Top1

### **üìâ Peores Resultados por Categor√≠a**
- **Degradaci√≥n m√°xima por expansi√≥n**: -74.73% (Expansiones extremas)
- **Peor Top1**: 2.1% (Expansiones masivas)
- **Peor MRR**: 0.1337 (Expansiones ultra-complejas)

## **Lecciones Aprendidas**

### **‚úÖ Estrategias Exitosas**
1. **Hibridaci√≥n MRF + Embeddings**: Mejora significativa del rendimiento
2. **Pesos adaptativos**: Optimizaci√≥n din√°mica seg√∫n caracter√≠sticas de la query
3. **Ensemble MRF**: Combinaci√≥n de m√∫ltiples configuraciones MRF
4. **SAPBERT-UMLS**: Modelo base superior para dominio m√©dico
5. **Fine-Tuning + Ensemble**: M√°xima precisi√≥n con especializaci√≥n biom√©dica
6. **Detecci√≥n l√©xica pura**: Rendimiento medio pero estable (35.4% Top1)

### **‚ùå Estrategias Fallidas**
1. **Expansi√≥n dimensional masiva**: Destruye el rendimiento del modelo
2. **Reducci√≥n dimensional agresiva**: P√©rdida cr√≠tica de informaci√≥n sem√°ntica
3. **Augmentaci√≥n sem√°ntica**: No mejora el rendimiento base
4. **Normalizaci√≥n inteligente**: Degrada la precisi√≥n Top1
5. **Hibridaci√≥n l√©xico-sem√°ntica desbalanceada**: Peso insuficiente para palabras clave (10%)

### **üéØ Lecciones Clave**
1. **La hibridaci√≥n l√©xico-sem√°ntica requiere balance cuidadoso de pesos y normalizaci√≥n**
2. **Los m√©todos simples pueden superar a los complejos mal configurados**
3. **La interferencia entre se√±ales puede degradar el rendimiento**
4. **La detecci√≥n l√©xica pura tiene valor independiente pero limitado**
5. **El fine-tuning especializado mejora dram√°ticamente el rendimiento biom√©dico**
6. **Los ensembles de modelos proporcionan mejoras incrementales significativas**

### **üéØ L√≠mites Identificados**
- **M√°ximo dimensiones adicionales**: 200 para mantener rendimiento
- **Mejor tipo de ruido**: Gaussiano controlado con escala 0.20
- **Ratio de varianza √≥ptimo**: 0.80-0.85 para preservaci√≥n sem√°ntica
- **Dimensionalidad m√≠nima**: 384 para mantener capacidad discriminativa

## **Impacto del Proyecto**

Este proyecto ha demostrado que:
1. **La hibridaci√≥n inteligente** puede mejorar significativamente el rendimiento de sistemas RAG
2. **Los modelos m√©dicos especializados** (SAPBERT-UMLS) superan a los modelos generales
3. **La expansi√≥n dimensional artificial** tiene beneficios limitados y riesgos significativos
4. **La optimizaci√≥n incremental** es m√°s efectiva que las transformaciones radicales
5. **El dominio m√©dico** requiere estrategias espec√≠ficas y no generales
6. **La hibridaci√≥n l√©xico-sem√°ntica** requiere balance cuidadoso de pesos y normalizaci√≥n
7. **El fine-tuning especializado** mejora dram√°ticamente el rendimiento en dominios espec√≠ficos
8. **Los ensembles de modelos** proporcionan mejoras incrementales significativas
9. **La detecci√≥n l√©xica pura** tiene valor independiente pero limitado para complementar enfoques sem√°nticos
