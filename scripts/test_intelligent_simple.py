#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Versi√≥n Simplificada del Sistema de Reducci√≥n de Dimensionalidad Inteligente
Autor: An√°lisis de Embeddings M√©dicos
Fecha: 2025
Objetivo: Probar Estrategias 4 y 5 de forma simplificada
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sentence_transformers import SentenceTransformer
import os
import warnings
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import json
warnings.filterwarnings('ignore')

# Configuraci√≥n de matplotlib para espa√±ol
plt.rcParams['font.size'] = 12
plt.rcParams['axes.unicode_minus'] = False

class SimpleIntelligentReducer:
    """Versi√≥n simplificada del sistema inteligente"""
    
    def __init__(self, model_path="all-mini-base", pnts_folder="PNTs", benchmark_folder="benchmark"):
        self.model_path = model_path
        self.pnts_folder = pnts_folder
        self.benchmark_folder = benchmark_folder
        self.model = None
        self.pnts_documents = []
        self.pnts_names = []
        self.benchmark_data = {}
        self.original_embeddings = None
        
    def load_model(self):
        """Carga el modelo de embeddings"""
        print("üîÑ Cargando modelo de embeddings...")
        try:
            self.model = SentenceTransformer(self.model_path)
            print(f"‚úÖ Modelo cargado: {self.model.get_sentence_embedding_dimension()} dimensiones")
            return True
        except Exception as e:
            print(f"‚ùå Error al cargar el modelo: {e}")
            return False
    
    def load_pnts_documents(self):
        """Carga todos los documentos PNTs"""
        print(f"üìÅ Cargando documentos PNTs desde: {self.pnts_folder}")
        
        if not os.path.exists(self.pnts_folder):
            print(f"‚ùå Error: Carpeta {self.pnts_folder} no encontrada")
            return False
        
        txt_files = [f for f in os.listdir(self.pnts_folder) if f.endswith('.txt')]
        
        for filename in txt_files:
            file_path = os.path.join(self.pnts_folder, filename)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    if content:
                        self.pnts_documents.append(content)
                        self.pnts_names.append(filename)
            except Exception as e:
                print(f"   ‚ö†Ô∏è Error al leer {filename}: {e}")
        
        print(f"‚úÖ Documentos cargados: {len(self.pnts_documents)}")
        return len(self.pnts_documents) > 0
    
    def load_benchmark_data(self):
        """Carga datos del benchmark"""
        print("üîÑ Cargando datos del benchmark...")
        
        # Cargar benchmark en catal√°n
        cat_file = os.path.join(self.benchmark_folder, "preguntas_con_docs_cat.json")
        if os.path.exists(cat_file):
            with open(cat_file, 'r', encoding='utf-8') as f:
                cat_data = json.load(f)
                self.benchmark_data['catalan'] = cat_data
                print(f"‚úÖ Benchmark catal√°n: {len(cat_data)} preguntas")
        
        # Cargar benchmark en espa√±ol
        es_file = os.path.join(self.benchmark_folder, "preguntas_con_docs_es.json")
        if os.path.exists(es_file):
            with open(es_file, 'r', encoding='utf-8') as f:
                es_data = json.load(f)
                self.benchmark_data['spanish'] = es_data
                print(f"‚úÖ Benchmark espa√±ol: {len(es_data)} preguntas")
    
    def generate_embeddings(self):
        """Genera embeddings para los documentos PNTs"""
        if self.model is None:
            print("‚ùå Error: Modelo no cargado")
            return False
        
        print("üîÑ Generando embeddings...")
        try:
            self.original_embeddings = self.model.encode(self.pnts_documents, show_progress_bar=True)
            print(f"‚úÖ Embeddings generados: {self.original_embeddings.shape}")
            return True
        except Exception as e:
            print(f"‚ùå Error al generar embeddings: {e}")
            return False
    
    def perform_pca_analysis(self, n_components=10):
        """Realiza an√°lisis PCA como baseline"""
        print(f"üîÑ Realizando PCA con {n_components} componentes...")
        
        # Normalizaci√≥n
        scaler = StandardScaler()
        embeddings_scaled = scaler.fit_transform(self.original_embeddings)
        
        # Aplicar PCA
        pca = PCA(n_components=n_components, random_state=42)
        embeddings_pca = pca.fit_transform(embeddings_scaled)
        
        print(f"‚úÖ PCA completado: {embeddings_pca.shape}")
        print(f"üìä Varianza explicada: {np.sum(pca.explained_variance_ratio_)*100:.2f}%")
        
        return embeddings_pca, pca
    
    def perform_tsne_analysis(self, n_components=2, perplexity=10):
        """Realiza an√°lisis t-SNE optimizado"""
        print(f"üîÑ Realizando t-SNE con {n_components} componentes y perplexity {perplexity}...")
        
        # Normalizaci√≥n
        scaler = StandardScaler()
        embeddings_scaled = scaler.fit_transform(self.original_embeddings)
        
        # Aplicar t-SNE
        tsne = TSNE(
            n_components=n_components,
            perplexity=perplexity,
            random_state=42,
            n_jobs=-1,
            verbose=1
        )
        
        embeddings_tsne = tsne.fit_transform(embeddings_scaled)
        
        print(f"‚úÖ t-SNE completado: {embeddings_tsne.shape}")
        return embeddings_tsne, tsne
    
    def calculate_advanced_similarity_metrics(self, embeddings):
        """Calcula m√©tricas de similitud avanzadas"""
        print("üîÑ Calculando m√©tricas de similitud avanzadas...")
        
        results = {}
        
        # 1. Cosine Similarity
        print("   üìä Calculando Cosine Similarity...")
        cosine_sim = cosine_similarity(embeddings)
        results['cosine_similarity'] = cosine_sim
        
        # 2. Euclidean Distance
        print("   üìè Calculando Euclidean Distance...")
        euclidean_dist = euclidean_distances(embeddings)
        results['euclidean_distance'] = euclidean_dist
        
        # 3. Hybrid Distance (Cosine + Euclidean)
        print("   üîÄ Calculando Hybrid Distance...")
        hybrid_dist = self._calculate_hybrid_distance(cosine_sim, euclidean_dist)
        results['hybrid_distance'] = hybrid_dist
        
        print("‚úÖ M√©tricas de similitud calculadas")
        return results
    
    def _calculate_hybrid_distance(self, cosine_sim, euclidean_dist):
        """Calcula distancia h√≠brida combinando cosine y euclidean"""
        # Normalizar ambas m√©tricas a [0,1]
        cosine_norm = (cosine_sim + 1) / 2  # Convertir [-1,1] a [0,1]
        euclidean_norm = euclidean_dist / np.max(euclidean_dist)
        
        # Combinar con pesos
        alpha = 0.6  # Peso para cosine
        hybrid_dist = alpha * cosine_norm + (1 - alpha) * euclidean_norm
        
        return hybrid_dist
    
    def evaluate_discrimination_quality(self, embeddings, method_name):
        """Eval√∫a la calidad de discriminaci√≥n de los embeddings"""
        print(f"üîç Evaluando calidad de discriminaci√≥n: {method_name}")
        
        # Calcular m√©tricas de separaci√≥n
        distances = euclidean_distances(embeddings)
        np.fill_diagonal(distances, np.inf)
        
        # Distancia m√≠nima promedio (mayor = mejor separaci√≥n)
        min_distances = np.min(distances, axis=1)
        avg_min_distance = np.mean(min_distances)
        
        # Ratio de varianza (mayor = mejor separaci√≥n)
        variance_ratio = np.var(embeddings) / np.var(self.original_embeddings)
        
        # Silhouette score aproximado
        silhouette_score = self._calculate_silhouette_score(embeddings)
        
        results = {
            'method': method_name,
            'avg_min_distance': avg_min_distance,
            'variance_ratio': variance_ratio,
            'silhouette_score': silhouette_score,
            'shape': embeddings.shape
        }
        
        print(f"   üìä Resultados:")
        print(f"      ‚Ä¢ Distancia m√≠nima promedio: {avg_min_distance:.4f}")
        print(f"      ‚Ä¢ Ratio de varianza: {variance_ratio:.4f}")
        print(f"      ‚Ä¢ Silhouette score: {silhouette_score:.4f}")
        
        return results
    
    def _calculate_silhouette_score(self, embeddings):
        """Calcula un score de silhouette aproximado"""
        try:
            from sklearn.metrics import silhouette_score
            from sklearn.cluster import KMeans
            
            # Determinar n√∫mero √≥ptimo de clusters
            n_clusters = min(8, len(embeddings) // 3)
            if n_clusters < 2:
                return 0.0
            
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(embeddings)
            
            silhouette_avg = silhouette_score(embeddings, cluster_labels)
            return silhouette_avg
        except Exception as e:
            print(f"      ‚ö†Ô∏è Error calculando silhouette: {e}")
            return 0.0
    
    def visualize_results(self, results_dict):
        """Visualiza todos los resultados"""
        print("üé® Generando visualizaciones...")
        
        # Crear figura con subplots
        fig, axes = plt.subplots(2, 2, figsize=(20, 16))
        fig.suptitle('An√°lisis de Reducci√≥n de Dimensionalidad Inteligente (Simplificado)', 
                     fontsize=20, fontweight='bold')
        
        methods = list(results_dict.keys())
        
        for i, method in enumerate(methods[:4]):  # M√°ximo 4 m√©todos
            row = i // 2
            col = i % 2
            
            if method in results_dict and 'embeddings' in results_dict[method]:
                embeddings = results_dict[method]['embeddings']
                
                if embeddings.shape[1] >= 2:
                    # Visualizaci√≥n 2D
                    axes[row, col].scatter(embeddings[:, 0], embeddings[:, 1], 
                                         alpha=0.7, s=50, c='blue')
                    axes[row, col].set_title(f'{method}', fontweight='bold')
                    axes[row, col].set_xlabel('Dimensi√≥n 1')
                    axes[row, col].set_ylabel('Dimensi√≥n 2')
                    axes[row, col].grid(True, alpha=0.3)
                else:
                    # Visualizaci√≥n 1D
                    axes[row, col].hist(embeddings.flatten(), bins=20, alpha=0.7, color='blue')
                    axes[row, col].set_title(f'{method} (1D)', fontweight='bold')
                    axes[row, col].set_xlabel('Valor')
                    axes[row, col].set_ylabel('Frecuencia')
        
        plt.tight_layout()
        plt.savefig('simple_intelligent_results.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("‚úÖ Visualizaciones guardadas en 'simple_intelligent_results.png'")
    
    def generate_report(self, results_dict, evaluation_results):
        """Genera reporte del an√°lisis"""
        print("üìä Generando reporte...")
        
        with open('simple_intelligent_report.txt', 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("REPORTE SIMPLIFICADO - ESTRATEGIAS 4 Y 5\n")
            f.write("Reducci√≥n de Dimensionalidad Inteligente y M√©tricas Avanzadas\n")
            f.write("=" * 80 + "\n\n")
            
            f.write("RESUMEN DE M√âTODOS IMPLEMENTADOS:\n")
            f.write("-" * 40 + "\n")
            
            for method, result in results_dict.items():
                if 'embeddings' in result:
                    f.write(f"\n{method}:\n")
                    f.write(f"  ‚Ä¢ Forma: {result['embeddings'].shape}\n")
            
            f.write("\nEVALUACI√ìN DE CALIDAD:\n")
            f.write("-" * 30 + "\n")
            
            for eval_result in evaluation_results:
                f.write(f"\n{eval_result['method']}:\n")
                f.write(f"  ‚Ä¢ Distancia m√≠nima promedio: {eval_result['avg_min_distance']:.4f}\n")
                f.write(f"  ‚Ä¢ Ratio de varianza: {eval_result['variance_ratio']:.4f}\n")
                f.write(f"  ‚Ä¢ Silhouette score: {eval_result['silhouette_score']:.4f}\n")
            
            f.write("\nRECOMENDACIONES:\n")
            f.write("-" * 20 + "\n")
            f.write("1. Usar m√©todo con mayor silhouette score para discriminaci√≥n\n")
            f.write("2. Considerar t-SNE para visualizaci√≥n 2D\n")
            f.write("3. Evaluar m√©tricas h√≠bridas para mejor rendimiento\n")
            f.write("4. Comparar con embeddings originales como baseline\n")
        
        print("‚úÖ Reporte generado: simple_intelligent_report.txt")

def main():
    """Funci√≥n principal simplificada"""
    print("üöÄ INICIANDO AN√ÅLISIS SIMPLIFICADO - ESTRATEGIAS 4 Y 5")
    print("=" * 80)
    print("Implementando:")
    print("‚Ä¢ Estrategia 4: Reducci√≥n de Dimensionalidad Inteligente (PCA + t-SNE)")
    print("‚Ä¢ Estrategia 5: M√©tricas de Similitud Avanzadas (Cosine + Euclidean + Hybrid)")
    print("=" * 80)
    
    # Crear analizador
    analyzer = SimpleIntelligentReducer()
    
    # Cargar modelo y datos
    if not analyzer.load_model():
        return
    
    if not analyzer.load_pnts_documents():
        return
    
    if not analyzer.load_benchmark_data():
        return
    
    if not analyzer.generate_embeddings():
        return
    
    # ESTRATEGIA 4: Reducci√≥n de Dimensionalidad Inteligente
    print("\n" + "="*60)
    print("üî¨ ESTRATEGIA 4: REDUCCI√ìN DE DIMENSIONALIDAD INTELIGENTE")
    print("="*60)
    
    results = {}
    evaluation_results = []
    
    # 1. PCA como baseline
    print("\nüìä 1. AN√ÅLISIS PCA (Baseline)")
    embeddings_pca, pca_reducer = analyzer.perform_pca_analysis(n_components=10)
    results['PCA_Baseline'] = {'embeddings': embeddings_pca, 'reducer': pca_reducer}
    
    # 2. t-SNE Optimizado
    print("\nüìä 2. AN√ÅLISIS t-SNE OPTIMIZADO")
    embeddings_tsne, tsne_reducer = analyzer.perform_tsne_analysis(perplexity=10)
    results['TSNE_Optimized'] = {'embeddings': embeddings_tsne, 'reducer': tsne_reducer}
    
    # ESTRATEGIA 5: M√©tricas de Similitud Avanzadas
    print("\n" + "="*60)
    print("üî¨ ESTRATEGIA 5: M√âTRICAS DE SIMILITUD AVANZADAS")
    print("="*60)
    
    # Calcular m√©tricas avanzadas para embeddings originales
    advanced_metrics = analyzer.calculate_advanced_similarity_metrics(analyzer.original_embeddings)
    results['Advanced_Metrics'] = advanced_metrics
    
    # Evaluar calidad de discriminaci√≥n
    print("\nüîç EVALUANDO CALIDAD DE DISCRIMINACI√ìN")
    print("-" * 50)
    
    for method_name in ['PCA_Baseline', 'TSNE_Optimized']:
        if method_name in results and 'embeddings' in results[method_name]:
            eval_result = analyzer.evaluate_discrimination_quality(
                results[method_name]['embeddings'], 
                method_name
            )
            evaluation_results.append(eval_result)
    
    # Evaluar embeddings originales como baseline
    baseline_eval = analyzer.evaluate_discrimination_quality(
        analyzer.original_embeddings, 
        'Original_Embeddings'
    )
    evaluation_results.append(baseline_eval)
    
    # Visualizar resultados
    analyzer.visualize_results(results)
    
    # Generar reporte
    analyzer.generate_report(results, evaluation_results)
    
    print("\nüéâ AN√ÅLISIS COMPLETADO EXITOSAMENTE!")
    print("üìÅ Archivos generados:")
    print("   - simple_intelligent_results.png")
    print("   - simple_intelligent_report.txt")
    
    # Mostrar resumen de resultados
    print("\nüìä RESUMEN DE RESULTADOS:")
    print("-" * 30)
    for eval_result in evaluation_results:
        print(f"   {eval_result['method']}: Silhouette={eval_result['silhouette_score']:.4f}, "
              f"Var_Ratio={eval_result['variance_ratio']:.4f}")

if __name__ == "__main__":
    main()
